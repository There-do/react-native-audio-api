---
sidebar_position: 2
---

import { ReadOnly } from '@site/src/components/Badges';

# WorkletNode

:::warning
This node is dependent on `react-native-worklets` and you need to install them in order to use this node. Refer to [getting-started page](/docs/fundamentals/getting-started#possible-additional-dependencies) for more info.
:::

The `WorkletNode` interface represents a node in the audio processing graph that can execute a worklet.

Worklets are a way to run JavaScript code in the audio rendering thread, allowing for low-latency audio processing. For more information, see our introduction [Introduction to worklets](/docs/worklets/worklets-introduction).
This node lets you execute a worklet on the UI thread. bufferLength specifies the size of the buffer that will be passed to the worklet on each call. The inputChannelCount specifies the number of channels that will be passed to the worklet.

## Constructor

```tsx
constructor(
  context: BaseAudioContext,
  runtime: AudioWorkletRuntime,
  callback: (audioData: Array<Float32Array>, channelCount: number) => void,
  bufferLength: number,
  inputChannelCount: number)
```
Or by using `BaseAudioContext` factory method:
[`BaseAudioContext.createWorkletNode(worklet, bufferLength, inputChannelCount, workletRuntime)`](/docs/core/base-audio-context#createworkletnode-)

## Example
```tsx
import { AudioContext, AudioRecorder, AudioManager } from 'react-native-audio-api';

AudioManager.setAudioSessionOptions({
    iosCategory: "playAndRecord",
    iosMode: "measurement",
    iosOptions: ["mixWithOthers"],
})

// This example shows how we can use a WorkletNode to process microphone audio data in real-time.
async function App() {
    const recorder = new AudioRecorder();

    const audioContext = new AudioContext({ sampleRate: 16000 });
    const worklet = (audioData: Array<Float32Array>, inputChannelCount: number) => {
        'worklet';
        // here you have access to the number of input channels and the audio data
        // audio data is a two dimensional array where first index is the channel number and second is buffer of exactly bufferLength size
        // !IMPORTANT: here you can only read audio data any modifications will not be reflected in the audio output of this node
        // !VERY IMPORTANT: please read the Known Issue section below
    };
    const workletNode = audioContext.createWorkletNode(worklet, 1024, 2, 'UIRuntime');
    const adapterNode = audioContext.createRecorderAdapter();

    const canSetAudioSessionActivity = await AudioManager.setAudioSessionActivity(true);
    if (!canSetAudioSessionActivity) {
        throw new Error("Could not activate the audio session");
    }
    adapterNode.connect(workletNode);
    workletNode.connect(audioContext.destination);
    recorder.connect(adapterNode);
    recorder.start();
    audioContext.resume();
}
```

## Properties
It has no own properties but inherits from [`AudioNode`](/docs/core/audio-node).

## Methods
It has no own methods but inherits from [`AudioNode`](/docs/core/audio-node).

## Known Issue
It might happen that the worklet side effect is not visible on the UI (when you are using UIRuntime kind). For example you have some animated style which depends on some shared value modified in the worklet.
This is happening because microtask queue is not always being flushed properly, bla bla bla...

To workaround this issue just add this line at the end of your worklet callback function:
```ts
requestAnimationFrame(() => {});
```
This will ensure that microtask queue is flushed and your UI will be updated properly. But be aware that this might have some performance implications so it is not included by default.
So use this only after confirming that your worklet side effects are not visible on the UI.
